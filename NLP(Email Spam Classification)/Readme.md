<h1>NLP -Email Spam Classification<br>
Author: Anthony Rodrigues</h1>
<pre>
<h3>
Applied Concepts : 
1)Data Ingestion - Importing the required libraries and data
  
2)Data Exploration, Cleaning and Preprocessing - Visualized the distribution of 
targets,Handled Null and Duplicate records, Parsed the records as the data was having
unstructured format.

3)Feature Engineering - Created length of words, characters and sentences features.
  
4)EDA - HeatMap, Histoplots, Pairplot (Visualized the relation between the features 
engineered and target variable ).
  
5)Data Preprocessing 2 - Even after the content was Parsed I could potentialy see some 
not required format for the Language tasks like the sender, receiver, date, time, etc.
So I extracted some patterns which were either containing only the content or mostly
the content with some noise(not reqd info over here).
  
6)WordClouds - Created wordclouds to visualize the Spam records content and Not Spam 
records content

7)Text Preprocessing - Tokenization, Lowercasing, Removing punctuation, special
characters and stop words, Stemming 

8)EDA 2 - Visualizing the 30 Most Frequent words in Spam data corpus and Not spam data
corpus to get an idea about what words will it most likely classify as spam or not 
spam.

9)Text Preprocessing 2 - Vectorization using TFIDF and CountVectorizor and Converting
the Transformations to arrays.

10)Train-Test Split - Using Stratified KFold to see which Models are consistent on all
the splits and capturing the best split.

11)Model Importing, Training and Evaluating - Using Best Classification models like 
SVC, RandomForest, Logistic Regression, XGB, etc

12)Model Building - As the Models trained are pretty accurate I tried to build a 
Voting  classifier Model with only Models having an accuray of over 98% but The Voting
Classifier didn't prove to be Beneficial,Used Stacking Classifier then with the models
passing the same accuracy threshold and it did improve the Solo models.

13)Pipeline Building - 
a)Created a python file with all the functions(parser, content_extractor, 
preprocessing_text_2, array_transformer) used in the process of Model Training.
b)Imported the functions and introduced them in a scikit-learn's Pipeline

14)Pipeline Training and Evaluating -
a)Imported raw data
b)fitted and transformed the preprocessor pipeline on the raw data
b)Used the best split from the Stratified Kfold for the Train test split
c)Built the model and inserted it in a pipeline
d)Trained the pipeline model and predicted it on Validation data
e)Further Tested on Testing data
f)Also tested on A spam Email generated by ChatGPT (without the spam words).

</pre><font face=verdona color=green>
Note The Packages are not uploaded but mentioned along with their versions in requirements.txt 
file download those and you're good to go 
